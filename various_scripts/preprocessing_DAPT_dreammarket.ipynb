{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing of Drug Dataset From Dreammarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import langdetect as ld\n",
    "import stanza\n",
    "from stanza.pipeline.processor import register_processor, Processor\n",
    "\n",
    "import time\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import phonenumbers\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = pd.read_pickle('intermediate_store/preprocessed_AMT_ads_V1.2.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove ITEM already annotated by APPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load reviewed annotation data\n",
    "with open('reviewed_data/initial_1300.json') as json_file:\n",
    "    rewiewed_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_dream_ids = []\n",
    "\n",
    "for review in rewiewed_json:\n",
    "    annotated_dream_ids.append(review['data']['dream_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11674, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10661, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled = df_shuffled[~df_shuffled['dream_id'].isin(annotated_dream_ids)]\n",
    "df_shuffled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove HTML encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled['clean_description'] = df_shuffled['clean_description'].str.replace('&#44', ',')\n",
    "df_shuffled['clean_description'] = df_shuffled['clean_description'].str.replace('&#39', '\\'')\n",
    "df_shuffled['clean_description'] = df_shuffled['clean_description'].str.replace('&#34', '\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        ONLY DOMESTIC BIG BUD XXL Very GOOD Quality Ca...\n",
       "2        Durgamata is a precious strain , it s has a un...\n",
       "3        Goodfellers is back. 4500 sales on AB always p...\n",
       "4        This listing is for. Pregabalin 300 mg x 56 Ta...\n",
       "5        Direct from US pharmacy. Real Adderall - not P...\n",
       "                               ...                        \n",
       "11669    This is a custom listing for previously approv...\n",
       "11670    New batch of ketamine shards this time. Pure c...\n",
       "11671    14g TOTAL. 7g HOMEGROWN BIG BUDDHA BLUE CHEESE...\n",
       "11672    This is for 20 OXYCONTIN 40 mg pills just like...\n",
       "11673    VitaminClub proudly offers you the highest and...\n",
       "Name: clean_description, Length: 10661, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.clean_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate item listings according to length into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_textLength(text):\n",
    "    if len(text)<100:\n",
    "        return 1\n",
    "    elif len(text)<250:\n",
    "        return 2\n",
    "    elif len(text)<500:\n",
    "        return 3\n",
    "    elif len(text)<750:\n",
    "        return 4\n",
    "    elif len(text)<1000:\n",
    "        return 5\n",
    "    elif len(text)<1500:\n",
    "        return 6\n",
    "    elif len(text)<2000:\n",
    "        return 7\n",
    "    elif len(text)<2500:\n",
    "        return 8\n",
    "    elif len(text)<3000:\n",
    "        return 9\n",
    "    \n",
    "df_shuffled[\"textLengthCat\"] = df_shuffled[\"clean_description\"].apply(lambda text: categorize_textLength(text))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_length(doc):\n",
    "    length=0\n",
    "    doc_dict = doc.to_dict()\n",
    "    for sent in doc_dict:\n",
    "        length+=len(sent)\n",
    "    return length\n",
    "#testdoc = df_shuffled.iloc[1]\n",
    "#get_doc_length(testdoc.doc)\n",
    "pd.set_option('display.max_rows', df_shuffled.shape[0])\n",
    "#df_shuffled.doc.apply(lambda doc: get_doc_length(doc)).sort_values(ascending=False)\n",
    "df_shuffled['doc_len'] = df_shuffled.doc.apply(lambda doc: get_doc_length(doc))\n",
    "#TODO remove super long ones in the future.\n",
    "#Hui Hui Hui das war knapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8016, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short=df_shuffled[df_shuffled['textLengthCat'] <= 5].copy()\n",
    "df_short=df_short[1900:].copy()\n",
    "#:100 in first batch\n",
    "#200:500 in second batch\n",
    "#500:1100 in thrid batch\n",
    "#1100:1600 in fourth batch\n",
    "#1600:1900 in fifth batch\n",
    "#--> 1900:end as DAPT\n",
    "\n",
    "\n",
    "df_long=df_shuffled[(df_shuffled['textLengthCat'] > 5 ) & (df_shuffled['doc_len'] <= 509)].copy()\n",
    "df_long=df_long[700:].copy()\n",
    "#Long Batches\n",
    "#:100 in first batch\n",
    "#100:300 in second batch\n",
    "#300:500 in third batch\n",
    "#500:700 in fourth batch\n",
    "# --> 700:end as DAPT\n",
    "\n",
    "dapt = pd.concat([df_short, df_long])\n",
    "dapt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapt[ 'clean_description'].to_csv(\"final_data/DAPT_DreamMarket1.0.txt\", sep = '\\t', quotechar='\\'', index=False, header=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10661, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER36",
   "language": "python",
   "name": "ner36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
