{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import time\n",
    "import swifter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Aggregated Report from File and download the jsons from links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 12)\n",
      "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'annotations', 'annotations:confidence',\n",
      "       'annotations_gold', 'clean_description', 'dream_id', 'name', 'p_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "run1=\"Aggregated_Report1722845\"\n",
    "run3=\"Aggregated_Report_1726283\"\n",
    "run4=\"Aggregated_Report_1726283_2\"\n",
    "run5=\"Aggregated_Report_1726283_3\"\n",
    "run6=\"Aggregated_Report_1734122\"\n",
    "\n",
    "filename = run6\n",
    "\n",
    "agg_report = pd.read_csv(\"appen_results/\" + filename + \".csv\")\n",
    "print(agg_report.shape)\n",
    "print(agg_report.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#AMT NAN annotations: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(417, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('#AMT NAN annotations:', agg_report.annotations.isna().sum()) # Remove those rows with a NAN annotation..\n",
    "agg_report = agg_report[agg_report.annotations.notna()].copy()\n",
    "agg_report.shape    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new Pickle File\n",
      "CPU times: user 18.5 s, sys: 644 ms, total: 19.1 s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#The annotations are for some reasons only embedded as link --> extra download needed.\n",
    "def download_json(row):\n",
    "    #print('Load Unit ID:', row['_unit_id'], ' row_index: ', row.name)\n",
    "    data = urllib.request.urlopen(row['annotations']).read()\n",
    "    output = json.loads(data)\n",
    "    return output\n",
    "\n",
    "#And Persist Results, since we don't wanna do this every time...\n",
    "if not os.path.exists('intermediate_store/' + filename + '.pickle'):\n",
    "    agg_report[\"anno_json\"] = agg_report.apply(lambda row: download_json(row), axis=1)\n",
    "    agg_report.to_pickle('intermediate_store/' + filename + '.pickle')\n",
    "    print(\"Created new Pickle File\")\n",
    "else:\n",
    "    agg_report = pd.read_pickle('intermediate_store/' + filename + '.pickle')\n",
    "    print(\"Loaded Pickle File\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove gold data and report Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall confidence mean:  0.7390856115107914\n",
      "Gold Data confidence mean:  0.8162367521367521\n",
      "New Data confidence mean:  0.7089966666666666\n"
     ]
    }
   ],
   "source": [
    "gold_data = agg_report[agg_report['_golden'] == True].copy()\n",
    "new_data = agg_report[agg_report['_golden'] == False].copy()\n",
    "\n",
    "print('Overall confidence mean: ', agg_report['annotations:confidence'].mean())\n",
    "print('Gold Data confidence mean: ', gold_data['annotations:confidence'].mean())\n",
    "print('New Data confidence mean: ', new_data['annotations:confidence'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove old and gold annotations  \n",
    "\n",
    "### TODO UPDATE DATE FOR EACH RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_report._last_judgment_at = pd.to_datetime(agg_report._last_judgment_at)\n",
    "comparsion_date = datetime.datetime(2021,2,20,0,0,0) # year, month, day etc..\n",
    "agg_report = agg_report[agg_report['_last_judgment_at'] >=  comparsion_date ].copy()\n",
    "agg_report = agg_report[agg_report['_golden'] ==  False ].copy()\n",
    "agg_report.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             ClearJuice Cartridges 510 Thread FE Only\n",
       "1    New!!sample listing Blotters LSD 220ug 2x (Fre...\n",
       "2    (Quantity x10,000) 2.5mg Xanax Bar RxPress G37...\n",
       "3                                   100g Heroin Afghan\n",
       "4      Genuine Pfizer Cytotec - 50 tablets - Free Ship\n",
       "5                    3.5g  Premium Royal Moroccan  30 \n",
       "6                                5 grams / Malana Hash\n",
       "7       \"1oz. \"\"Purple Sizzurp\"\" codeine/promethazine\"\n",
       "8                         1g Mr. Suprise Blok [AAA+++]\n",
       "9                       1x 65mg THC Organic Nerds Rope\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_report.head(10).name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Labelstudio Example format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('appen_results/label_studio_example.json') as json_file:\n",
    " #   label_studio = json.load(json_file)\n",
    "#label_studio[3]['completions'][0]['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toplevel: dict_keys(['completions', 'data', 'id'])\n",
    "# Completions \n",
    "    #--> List --> only one for the beginning [0]\n",
    "        # dict_keys(['created_at', 'id', 'lead_time', 'result'])\n",
    "            #created_at --> Unix time\n",
    "            #id --> unit_id from appen\n",
    "            #lead_time --> I don't know set to default\n",
    "            # Result --> List of all label dicts\n",
    "                #Dict Items:\n",
    "                    #From_name: No annotator ID --> default 'Appen'\n",
    "                    # id --> span_id from annotation\n",
    "                    #to_name: 'text'\n",
    "                    # type : 'labels'\n",
    "                    # value : dict\n",
    "                        #start: char id\n",
    "                        #end: char id\n",
    "                        #labels:['Drug']\n",
    "                        #text: text of token/full span\n",
    "#data:dict\n",
    "    #dream_id\n",
    "    #p_id\n",
    "    #description\n",
    "    #name\n",
    "#id:unique id for labelstudio.    \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_annotation(span_dict, classname):\n",
    "     #initialize tokenspan min range\n",
    "    startIdx=span_dict['tokens'][0]['startIdx']\n",
    "    endIdx=span_dict['tokens'][0]['endIdx']\n",
    "    text=''\n",
    "\n",
    "    #Get start and end of token span\n",
    "    for token_dict in span_dict['tokens']:\n",
    "        if token_dict['startIdx'] < startIdx:\n",
    "            startIdx = token_dict['startIdx']\n",
    "        if token_dict['endIdx'] > endIdx:\n",
    "            endIdx = token_dict['endIdx']\n",
    "        text = text + ' ' +   token_dict['text']\n",
    "        \n",
    "    return {'from_name': 'label',\n",
    "                       'id': span_dict['id'],\n",
    "                       'to_name': 'text',\n",
    "                       'type': 'labels',\n",
    "                       'value':{'end':endIdx,\n",
    "                                    'labels': [classname],\n",
    "                                    'text':text.strip(),\n",
    "                                    'start':startIdx}\n",
    "    }\n",
    "\n",
    "def get_result_json(json, ind):\n",
    "    result=[]\n",
    "    #print(ind)\n",
    "    for span_dict in json['spans']:\n",
    "        if span_dict['annotated_by'] == 'human' and len(span_dict['classnames']) > 0:\n",
    "            if len(span_dict['classnames']) > 1:\n",
    "                print('WTF is that!', span_dict['classnames'])\n",
    "            \n",
    "            elif span_dict['classnames'][0] == 'Drug' :\n",
    "                result.append(get_span_annotation(span_dict, 'Drug'))\n",
    "            elif span_dict['classnames'][0] == 'None':\n",
    "                result.append(get_span_annotation(span_dict, 'None'))\n",
    "            else:\n",
    "                print('I Found a NONE!!!!')\n",
    "    return result\n",
    "\n",
    "            \n",
    "def create_labelstudio_data(agg_row):\n",
    "    data={'dream_id':agg_row.dream_id, 'name':agg_row['name'], 'p_id':agg_row.p_id, \n",
    "          'clean_description':agg_row.clean_description, 'golden':agg_row['_golden'] }\n",
    "\n",
    "    completions={'created_at': int(time.time()),\n",
    "                'id':agg_row._unit_id,\n",
    "                'lead_time':10.00,        #I have no clue what lead time is.\n",
    "                'result':get_result_json(agg_row.anno_json, agg_row.name)\n",
    "                }\n",
    "    \n",
    "    return {'completions':[completions], 'data':data, 'id':agg_row._unit_id}\n",
    "    \n",
    "\n",
    "agg_report['labelstudio_json'] = agg_report.apply(lambda row: create_labelstudio_data(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_report.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write TO File\n",
    "with open('appen_results/label_studio_' + filename + '.json', 'w') as json_file:\n",
    "    json.dump(agg_report['labelstudio_json'].to_list(), json_file, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i, row in agg_report.iterrows():\\n    print('Overall Confidence: ', row['annotations:confidence'], ' of row ', i, ' unitID: ', row['_unit_id'])\\n    for span in row['anno_json']['spans']:\\n        if 'confidence' in span:\\n            print('   span Conf: ', span['confidence'])\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Investigate Confidence values.\n",
    "'''for i, row in agg_report.iterrows():\n",
    "    print('Overall Confidence: ', row['annotations:confidence'], ' of row ', i, ' unitID: ', row['_unit_id'])\n",
    "    for span in row['anno_json']['spans']:\n",
    "        if 'confidence' in span:\n",
    "            print('   span Conf: ', span['confidence'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run1\n",
    "#Overall Confidence:  0.7625  of row  140  unitID:  2945786522\n",
    "#   span Conf:  0.8667\n",
    "#   span Conf:  0.6583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7089966666666666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_report['annotations:confidence'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER36",
   "language": "python",
   "name": "ner36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
